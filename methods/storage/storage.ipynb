{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your models in PyEMMA\n",
    "==========================\n",
    "\n",
    "Most of the Estimators and Models in PyEMMA are serializable. If a given Estimator or Model can be saved to disk,\n",
    "it provides a **save** method. In this notebook we will explain the basic concepts of file handling.\n",
    "\n",
    "We try our best to provide **future** compatiblity of already saved data. This means it should always be possible to load\n",
    "data with a newer version of the software, but you can not do reverse, eg. load a model saved by a new version with an old version of PyEMMA.\n",
    "\n",
    "If you are interested in the technical background, go ahead and read the source code (it is not that much actually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyemma\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some syntetical data with 10 states\n",
    "dtrajs = [np.random.randint(0, 10, size=10000) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianMSM(conf=0.95, connectivity='largest', count_mode='effective',\n",
      "      dt_traj='1 step', lag=10, mincount_connectivity='1/n', nsamples=100,\n",
      "      nsteps=3, reversible=True, show_progress=False, sparse=False,\n",
      "      statdist_constraint=None)\n"
     ]
    }
   ],
   "source": [
    "# estimate a Baysian Markov state model\n",
    "bmsm = pyemma.msm.bayesian_markov_model(dtrajs, lag=10)\n",
    "print(bmsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the estimator (which contains the model) to disk, We delete any existing file to avoid an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.unlink('my_models.h5')\n",
    "except FileNotFoundError: pass\n",
    "\n",
    "# now save our model\n",
    "bmsm.save('my_models.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now restore the model, by simply invoking pyemma.load function with our file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianMSM(conf=0.95, connectivity='largest', count_mode='effective',\n",
       "      dt_traj='1 step', lag=10, mincount_connectivity='1/n', nsamples=100,\n",
       "      nsteps=3, reversible=True, show_progress=False, sparse=False,\n",
       "      statdist_constraint=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyemma.load('my_models.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can save multiple models in one file. Because HDF5 acts like a file system, we have each model in a separate \"folder\", which is completely independent of the other models. We now change a parameter during estimation and save the estimator again in the same file, but in a different \"folder\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianMSM(conf=0.95, connectivity='largest', count_mode='effective',\n",
      "      dt_traj='1 step', lag=100, mincount_connectivity='1/n', nsamples=100,\n",
      "      nsteps=3, reversible=True, show_progress=False, sparse=False,\n",
      "      statdist_constraint=None)\n"
     ]
    }
   ],
   "source": [
    "bmsm.estimate(dtrajs, lag=100)\n",
    "print(bmsm)\n",
    "bmsm.save('my_models.h5', model_name='lag100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise when we want to restore the model with the new name, we have to pass it to the load function accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianMSM(conf=0.95, connectivity='largest', count_mode='effective',\n",
       "      dt_traj='1 step', lag=100, mincount_connectivity='1/n', nsamples=100,\n",
       "      nsteps=3, reversible=True, show_progress=False, sparse=False,\n",
       "      statdist_constraint=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyemma.load('my_models.h5', model_name='lag100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noted, there is no need to pass a model name. For convenience we always save under model_name \"latest\", if the argument is not provided. To check which models are contained in a file, we provide a command line tool named \"pyemma_list_models\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: pyemma_list_models [-h] [--json] [--recursive] [-v] files [files ...]\r\n",
      "pyemma_list_models: error: the following arguments are required: files\r\n"
     ]
    }
   ],
   "source": [
    "! pyemma_list_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyEMMA models\r\n",
      "=============\r\n",
      "\r\n",
      "file: my_models.h5\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "1. name: lag100\r\n",
      "created: 1515632708.0470107\r\n",
      "BayesianMSM(conf=0.95, connectivity='largest', count_mode='effective',\r\n",
      "      dt_traj='1 step', lag=100, mincount_connectivity='1/n', nsamples=100,\r\n",
      "      nsteps=3, reversible=True, show_progress=False, sparse=False,\r\n",
      "      statdist_constraint=None)\r\n",
      "2. name: latest\r\n",
      "created: 1515632707.0779583\r\n",
      "BayesianMSM(conf=0.95, connectivity='largest', count_mode='effective',\r\n",
      "      dt_traj='1 step', lag=10, mincount_connectivity='1/n', nsamples=100,\r\n",
      "      nsteps=3, reversible=True, show_progress=False, sparse=False,\r\n",
      "      statdist_constraint=None)\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! pyemma_list_models my_models.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check the list of already stored models directly in PyEMMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available models: dict_keys(['lag100', 'latest'])\n",
      "--------------------------------------------------------------------------------\n",
      "detailed:\n",
      "{'lag100': {'class_repr': \"BayesianMSM(conf=0.95, connectivity='largest', \"\n",
      "                          \"count_mode='effective',\\n\"\n",
      "                          \"      dt_traj='1 step', lag=100, \"\n",
      "                          \"mincount_connectivity='1/n', nsamples=100,\\n\"\n",
      "                          '      nsteps=3, reversible=True, '\n",
      "                          'show_progress=False, sparse=False,\\n'\n",
      "                          '      statdist_constraint=None)',\n",
      "            'class_str': \"BayesianMSM(conf=0.95, connectivity='largest', \"\n",
      "                         \"count_mode='effective',\\n\"\n",
      "                         \"      dt_traj='1 step', lag=100, \"\n",
      "                         \"mincount_connectivity='1/n', nsamples=100,\\n\"\n",
      "                         '      nsteps=3, reversible=True, '\n",
      "                         'show_progress=False, sparse=False,\\n'\n",
      "                         '      statdist_constraint=None)',\n",
      "            'created': 1515632708.0470107,\n",
      "            'created_readable': 'Thu Jan 11 02:05:08 2018',\n",
      "            'digest': '90fa5337c777ef0d005e8c22c17357c1e762ad0319686fefddc1ef58d8268e51',\n",
      "            'pyemma_version': '2.4+899.gc815449c.dirty',\n",
      "            'saved_streaming_chain': False},\n",
      " 'latest': {'class_repr': \"BayesianMSM(conf=0.95, connectivity='largest', \"\n",
      "                          \"count_mode='effective',\\n\"\n",
      "                          \"      dt_traj='1 step', lag=10, \"\n",
      "                          \"mincount_connectivity='1/n', nsamples=100,\\n\"\n",
      "                          '      nsteps=3, reversible=True, '\n",
      "                          'show_progress=False, sparse=False,\\n'\n",
      "                          '      statdist_constraint=None)',\n",
      "            'class_str': \"BayesianMSM(conf=0.95, connectivity='largest', \"\n",
      "                         \"count_mode='effective',\\n\"\n",
      "                         \"      dt_traj='1 step', lag=10, \"\n",
      "                         \"mincount_connectivity='1/n', nsamples=100,\\n\"\n",
      "                         '      nsteps=3, reversible=True, '\n",
      "                         'show_progress=False, sparse=False,\\n'\n",
      "                         '      statdist_constraint=None)',\n",
      "            'created': 1515632707.0779583,\n",
      "            'created_readable': 'Thu Jan 11 02:05:07 2018',\n",
      "            'digest': '9ad0885f58e76e56a0fcf194bb4fd9a1ab90e6a7338c3d1c892bcbca62e6882c',\n",
      "            'pyemma_version': '2.4+899.gc815449c.dirty',\n",
      "            'saved_streaming_chain': False}}\n"
     ]
    }
   ],
   "source": [
    "content = pyemma.list_models('my_models.h5')\n",
    "print(\"available models:\", content.keys())\n",
    "print(\"-\" * 80)\n",
    "print(\"detailed:\")\n",
    "pprint.pprint(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwriting existing models is also possible, but we have to tell the save method, that we want to overwrite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-01-18 02:05:11 pyemma.msm.estimators.bayesian_msm.BayesianMSM[0] ERROR    During saving the object BayesianMSM(conf=0.95, connectivity='largest', count_mode='effective',\n",
      "      dt_traj='1 step', lag=100, mincount_connectivity='1/n', nsamples=100,\n",
      "      nsteps=3, reversible=True, show_progress=False, sparse=False,\n",
      "      statdist_constraint=None)\") the following error occurred: model \"latest\" already exists. Either use overwrite=True, or use a different name/file.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marscher/workspace/pyemma/pyemma/_base/serialization/serialization.py\", line 224, in save\n",
      "    f.add_serializable(model_name, obj=self, overwrite=overwrite, save_streaming_chain=save_streaming_chain)\n",
      "  File \"/home/marscher/workspace/pyemma/pyemma/_base/serialization/h5file.py\", line 120, in add_serializable\n",
      "    self._set_group(name, overwrite)\n",
      "  File \"/home/marscher/workspace/pyemma/pyemma/_base/serialization/h5file.py\", line 66, in _set_group\n",
      "    ' or use a different name/file.'.format(name=name))\n",
      "RuntimeError: model \"latest\" already exists. Either use overwrite=True, or use a different name/file.\n",
      "can not save: model \"latest\" already exists. Either use overwrite=True, or use a different name/file.\n"
     ]
    }
   ],
   "source": [
    "# we now expect that we get a failure, because the model already exists in the file.\n",
    "try:\n",
    "    bmsm.save('my_models.h5')\n",
    "except RuntimeError as e:\n",
    "    print(\"can not save:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-01-18 02:05:11 pyemma._base.serialization.h5file INFO     overwriting model \"latest\" in file /\n"
     ]
    }
   ],
   "source": [
    "bmsm.save('my_models.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the storage tutorial of PyEMMA. Happy saving!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
